{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import shutil\n",
    "#import os\n",
    "import json\n",
    "import sources.REmodeling as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG: \n",
    "    def __init__(this,\n",
    "            #EPS = 1e-8, \n",
    "            EPOCHS = 5, # 3~5\n",
    "            BATCH_SIZE = 16, # 8, 32\n",
    "            LEARNING_RATE = 3e-5, # 1e-5\n",
    "            MAX_LENGTH = 128, \n",
    "            ENCODER_TYPE = 'bert-base', # large, RoBERTa, DeBERTa\n",
    "            OPTIMIZER ='adamw',   \n",
    "            DEVICE_TYPE = \"cuda\", # Cuda or alternative\n",
    "            SAVE_MODEL=False,\n",
    "            TASK='RE-classification'):\n",
    "        this.EPOCHS=EPOCHS\n",
    "        this.BATCH_SIZE=BATCH_SIZE\n",
    "        this.LEARNING_RATE = LEARNING_RATE\n",
    "        this.MAX_LENGTH = MAX_LENGTH\n",
    "        this.ENCODER_TYPE = ENCODER_TYPE\n",
    "        this.OPTIMIZER = OPTIMIZER\n",
    "        this.DEVICE_TYPE = DEVICE_TYPE\n",
    "        this.SAVE_MODEL=SAVE_MODEL\n",
    "        this.TASK=TASK\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs=[]\n",
    "types=['bert-large','roberta-large']\n",
    "for type in types:\n",
    "    for eps in [3,5,8]:\n",
    "        configs.append(CONFIG(ENCODER_TYPE=type,EPOCHS=eps))\n",
    "    for lr in [1e-5,1e-4]:\n",
    "        configs.append(CONFIG(ENCODER_TYPE=type,LEARNING_RATE=lr))\n",
    "    if configs[-1].ENCODER_TYPE=='bert-large' and configs[-1].EPOCHS==5 and configs[-1].LEARNING_RATE==3e-5:\n",
    "        configs[-1].SAVE_MODLE=True\n",
    "    if configs[-1].ENCODER_TYPE=='roberta-large' and configs[-1].EPOCHS==5 and configs[-1].LEARNING_RATE==3e-5:\n",
    "        configs[-1].SAVE_MODLE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Datapack:\n",
    "    def __init__(this,train,test,val):\n",
    "        this.test_ds,this.reladict,this.testx,this.testy=this.load_dataset(test)\n",
    "        this.valid_ds,reladict,this.validx,this.validy=this.load_dataset(val,this.reladict,shuffle=True)\n",
    "        this.train_ds,this.reladict,this.trainx,this.trainy=this.load_dataset(train,this.reladict,shuffle=True)\n",
    "        this.invdict=np.zeros(len(this.reladict)).tolist()\n",
    "        for k,v in reladict.items():\n",
    "            this.invdict[v]=k\n",
    "        \n",
    "    def load_dataset(this,path,reladict={},shuffle=False):\n",
    "        with open(path,'r',encoding='UTF-8') as f:\n",
    "            data=[json.loads(line) for line in f]\n",
    "        sent=[]\n",
    "        relation=[]\n",
    "        for d in data:\n",
    "            token=d['token']\n",
    "            for i in range(d['h']['pos'][0],d['h']['pos'][1]):\n",
    "                token[i]='[MASK]'\n",
    "            for i in range(d['t']['pos'][0],d['t']['pos'][1]):\n",
    "                token[i]='[MASK]'\n",
    "            sent.append([' '.join(token)])\n",
    "            if reladict.get(d['relation'],False)==False:\n",
    "                reladict.setdefault(d['relation'],len(reladict))\n",
    "            relation.append(reladict[d['relation']])\n",
    "        temp=np.zeros(shape=(len(relation),len(reladict)))\n",
    "        #print(temp.shape)\n",
    "        #print(reladict)\n",
    "        for i in range(len(relation)):\n",
    "            temp[i][relation[i]]=1\n",
    "        if shuffle:\n",
    "            data=tf.data.Dataset.from_tensor_slices((sent,temp)).shuffle(5000).batch(configs[0].BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        else:\n",
    "            data=tf.data.Dataset.from_tensor_slices((sent,temp)).batch(configs[0].BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        return data,reladict,sent,relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "datapack=Datapack('semeval_train.txt','semeval_test.txt','semeval_val.txt')\n",
    "#for text_batch, label_batch in train_ds.take(1):\n",
    "  #for i in range(3):\n",
    "    #print(f'Review: {text_batch.numpy()[i]}')\n",
    "    #label = label_batch.numpy()[i]\n",
    "    #print(f'Label : {label}')\n",
    "    #print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('results/NRE_test_result.json','w',encoding='UTF-8')as f:\n",
    "        json.dump({},f,indent=2)\n",
    "n=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=CONFIG(ENCODER_TYPE='roberta-large')\n",
    "model,result=mod.modeling(config,datapack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(n,len(configs)):\n",
    "#    model,result=mod.modeling(configs[i],datapack)\n",
    "#    n=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['Result']['Weighted'])\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
