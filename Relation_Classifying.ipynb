{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Severus\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Severus\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import shutil\n",
    "#import os\n",
    "import json\n",
    "import sources.REmodeling as mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG: \n",
    "    EPS = 1e-8 \n",
    "    EPOCHS = 3 # 3~5\n",
    "    BATCH_SIZE = 16 # 8, 32\n",
    "    LEARNING_RATE = 3e-5 # 1e-5\n",
    "    MAX_LENGTH = 128 # 256\n",
    "    ENCODER_TYPE = 'bert-base' # large, RoBERTa, DeBERTa\n",
    "    OPTIMIZER ='adamw'   \n",
    "    DEVICE_TYPE = \"cuda\" # Cuda or alternative\n",
    "    SAVE_MODEL=False\n",
    "    TASK='RE-classification'\n",
    "config=CONFIG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Datapack:\n",
    "    def __init__(this,train,test,val):\n",
    "        this.test_ds,this.reladict,this.testx,this.testy=this.load_dataset(test)\n",
    "        this.valid_ds,reladict,this.validx,this.validy=this.load_dataset(val,this.reladict,shuffle=True)\n",
    "        this.train_ds,this.reladict,this.trainx,this.trainy=this.load_dataset(train,this.reladict,shuffle=True)\n",
    "        this.invdict=np.zeros(len(this.reladict)).tolist()\n",
    "        for k,v in reladict.items():\n",
    "            this.invdict[v]=k\n",
    "        \n",
    "    def load_dataset(this,path,reladict={},shuffle=False):\n",
    "        with open(path,'r',encoding='UTF-8') as f:\n",
    "            data=[json.loads(line) for line in f]\n",
    "        sent=[]\n",
    "        relation=[]\n",
    "        for d in data:\n",
    "            token=d['token']\n",
    "            for i in range(d['h']['pos'][0],d['h']['pos'][1]):\n",
    "                token[i]='[MASK]'\n",
    "            for i in range(d['t']['pos'][0],d['t']['pos'][1]):\n",
    "                token[i]='[MASK]'\n",
    "            sent.append([' '.join(token)])\n",
    "            if reladict.get(d['relation'],False)==False:\n",
    "                reladict.setdefault(d['relation'],len(reladict))\n",
    "            relation.append(reladict[d['relation']])\n",
    "        temp=np.zeros(shape=(len(relation),len(reladict)))\n",
    "        #print(temp.shape)\n",
    "        #print(reladict)\n",
    "        for i in range(len(relation)):\n",
    "            temp[i][relation[i]]=1\n",
    "        if shuffle:\n",
    "            data=tf.data.Dataset.from_tensor_slices((sent,temp)).shuffle(5000).batch(CONFIG.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        else:\n",
    "            data=tf.data.Dataset.from_tensor_slices((sent,temp)).batch(CONFIG.BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "        return data,reladict,sent,relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "datapack=Datapack('semeval_train.txt','semeval_train.txt','semeval_train.txt')\n",
    "#for text_batch, label_batch in train_ds.take(1):\n",
    "  #for i in range(3):\n",
    "    #print(f'Review: {text_batch.numpy()[i]}')\n",
    "    #label = label_batch.numpy()[i]\n",
    "    #print(f'Label : {label}')\n",
    "    #print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open('results/NRE_test_result.json','w',encoding='UTF-8')as f:\n",
    "        json.dump({},f,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " Preprocessor/Tokenizer (KerasL  {'input_word_ids':   0          ['text[0][0]']                   \n",
      " ayer)                          (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " Encoder (KerasLayer)           {'pooled_output': (  109482241   ['Preprocessor/Tokenizer[0][0]', \n",
      "                                None, 768),                       'Preprocessor/Tokenizer[0][1]', \n",
      "                                 'sequence_output':               'Preprocessor/Tokenizer[0][2]'] \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['Encoder[0][13]']               \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 18)           13842       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,496,083\n",
      "Trainable params: 109,496,082\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "407/407 [==============================] - 139s 312ms/step - loss: 1.9190 - categorical_accuracy: 0.4152 - val_loss: 0.8747 - val_categorical_accuracy: 0.7343\n",
      "Epoch 2/3\n",
      "407/407 [==============================] - 126s 310ms/step - loss: 0.8593 - categorical_accuracy: 0.7354 - val_loss: 0.5244 - val_categorical_accuracy: 0.8393\n",
      "Epoch 3/3\n",
      "407/407 [==============================] - 129s 317ms/step - loss: 0.5593 - categorical_accuracy: 0.8291 - val_loss: 0.3917 - val_categorical_accuracy: 0.8843\n",
      "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy'])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14460\\3274359291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatapack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\Project\\py\\KN\\NER\\sources\\REmodeling.py\u001b[0m in \u001b[0;36mmodeling\u001b[1;34m(config, datapack)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mtss_time\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[0mtse_time\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mtest_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtse_time\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtss_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testx' is not defined"
     ]
    }
   ],
   "source": [
    "result,model=mod.modeling(config,datapack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
