{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b82382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Hugging Face Transformers imports\n",
    "from transformers import BertModel, BertTokenizer, BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "# Scikit-learn metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# TQDM for progress bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class Bert_BiDirectional_LSTM(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_labels, hidden_dim=768, lstm_layers=1, dropout=0.1):\n",
    "        super(Bert_BiDirectional_LSTM, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=lstm_layers, \n",
    "                            bidirectional=True, \n",
    "                            batch_first=True,\n",
    "                            dropout=dropout if lstm_layers > 1 else 0)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_labels)  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "\n",
    "        lstm_output, _ = self.lstm(sequence_output)\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        logits = self.fc(lstm_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e93dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BERTBASE (L=12, H=768, A=12, Total Param- eters=110M) and \\n   BERTLARGE (L=24, H=1024, A=16, Total Parameters=340M).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_to_dataframe(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "class CONFIG: \n",
    "    EPS = 1e-8 \n",
    "    EPOCHS = 5 # 3~5\n",
    "    BATCH_SIZE = 16 # 8, 32\n",
    "    LEARNING_RATE = 2e-4 # 1e-5\n",
    "    MAX_LENGTH = 512 # 256\n",
    "    BERT_MODEL_NAME = 'bert-base-uncased' # large, RoBERTa, DeBERTa\n",
    "    DEVICE_NAME = \"mps\" # Cuda or alternative\n",
    "\n",
    "'''BERTBASE (L=12, H=768, A=12, Total Param- eters=110M) and \n",
    "   BERTLARGE (L=24, H=1024, A=16, Total Parameters=340M).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9cc552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data_to_dataframe('semeval_train.txt')\n",
    "val_df = load_data_to_dataframe('semeval_val.txt')\n",
    "test_df = load_data_to_dataframe('semeval_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61c8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(CONFIG.BERT_MODEL_NAME)\n",
    "\n",
    "def tokenize_and_align_labels(df, tokenizer, label_map, max_length=CONFIG.MAX_LENGTH):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    label_ids = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['token']\n",
    "        labels = ['O']*len(text)  \n",
    "\n",
    "        h_start, h_end = row['h']['pos']\n",
    "        t_start, t_end = row['t']['pos']\n",
    "        labels[h_start:h_end] = ['H']*(h_end - h_start)\n",
    "        labels[t_start:t_end] = ['T']*(t_end - t_start)\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(text,\n",
    "                                             add_special_tokens=True,      \n",
    "                                             max_length=max_length,       \n",
    "                                             padding='max_length',\n",
    "                                             return_attention_mask=True,  \n",
    "                                             is_split_into_words=True,\n",
    "                                             return_tensors='pt')\n",
    "\n",
    "        numeric_labels = [label_map[label] for label in labels]\n",
    "        numeric_labels = [label_map['O']] + numeric_labels[:max_length-2] + [label_map['O']]*(max_length - len(numeric_labels) - 1)\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "        label_ids.append(torch.tensor(numeric_labels))\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
    "    label_ids = torch.stack(label_ids, dim=0)\n",
    "    return input_ids, attention_masks, token_type_ids, label_ids\n",
    "\n",
    "label_map = {'O': 0, 'H': 1, 'T': 2}  \n",
    "\n",
    "train_inputs, train_masks, train_type_ids, train_labels = tokenize_and_align_labels(train_df, tokenizer, label_map)\n",
    "val_inputs, val_masks, val_type_ids, val_labels = tokenize_and_align_labels(val_df, tokenizer, label_map)\n",
    "test_inputs, test_masks, test_type_ids, test_labels = tokenize_and_align_labels(test_df, tokenizer, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e382b4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bert_BiDirectional_LSTM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(768, 768, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=1536, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bert_BiDirectional_LSTM(CONFIG.BERT_MODEL_NAME, num_labels = 3,)\n",
    "device = torch.device(CONFIG.DEVICE_NAME)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac649581",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = CONFIG.BATCH_SIZE\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "validation_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679c3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seowonduk/anaconda3/envs/deep_learning/lib/python3.12/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.mps.empty_cache()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                  lr=CONFIG.LEARNING_RATE, \n",
    "                  eps=CONFIG.EPS)\n",
    "\n",
    "epochs = CONFIG.EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd597d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dataloader, model, label_map):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs  \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        batch_predictions = np.argmax(logits, axis=2)\n",
    "        \n",
    "        predictions.extend([list(p) for p in batch_predictions])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    flat_predictions, flat_true_labels = [], []\n",
    "    for prediction, true_label in zip(predictions, true_labels):\n",
    "        for p, t in zip(prediction, true_label):\n",
    "            if t != label_map['O']:  \n",
    "                flat_predictions.append(p)\n",
    "                flat_true_labels.append(t)\n",
    "    \n",
    "    accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "    precision = precision_score(flat_true_labels, flat_predictions, average='weighted', zero_division=0)\n",
    "    recall = recall_score(flat_true_labels, flat_predictions, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(flat_true_labels, flat_predictions, average='weighted', zero_division=0)\n",
    "    report = classification_report(flat_true_labels, flat_predictions, target_names=label_map.keys(), zero_division=0)\n",
    "\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad131d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_stats = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": [],\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012ac962",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=CONFIG.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "831b5a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ea81795663466093e83b88bc112be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1 Started --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7509422c9d524aa1966e2457be0562fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Average Training Loss: 0.016093471394142442\n",
      "Epoch 1: Average Validation Loss: 0.007846244427553833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759e0ca3230f4eecbc6772e4f962b343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           O       0.00      0.00      0.00         0\n",
      "           H       0.97      0.67      0.79      2789\n",
      "           T       0.91      0.50      0.65      2874\n",
      "\n",
      "    accuracy                           0.58      5663\n",
      "   macro avg       0.63      0.39      0.48      5663\n",
      "weighted avg       0.94      0.58      0.72      5663\n",
      "\n",
      "Epoch 0: Test Metrics: Accuracy=0.5813173229736889, Precision=0.9440373635840386, Recall=0.5813173229736889, F1 Score=0.7174736662760671\n",
      "-- Epoch 2 Started --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e683a243afd1414ebe8103060b718069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Average Training Loss: 0.006434023950056743\n",
      "Epoch 2: Average Validation Loss: 0.007044660160318017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f894326d6cc9403ea8e86289a8c0b4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           O       0.00      0.00      0.00         0\n",
      "           H       0.98      0.68      0.80      2789\n",
      "           T       0.93      0.51      0.66      2874\n",
      "\n",
      "    accuracy                           0.59      5663\n",
      "   macro avg       0.64      0.39      0.49      5663\n",
      "weighted avg       0.95      0.59      0.73      5663\n",
      "\n",
      "Epoch 1: Test Metrics: Accuracy=0.5899699805756666, Precision=0.95433328134315, Recall=0.5899699805756666, F1 Score=0.7267476349405455\n",
      "-- Epoch 3 Started --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b188f432f1c14754bd666258f8c4b01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Average Training Loss: 0.004764049011053797\n",
      "Epoch 3: Average Validation Loss: 0.007217457295058572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ab70efb6984c4280fa9b3ba4322ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           O       0.00      0.00      0.00         0\n",
      "           H       0.97      0.69      0.81      2789\n",
      "           T       0.94      0.55      0.70      2874\n",
      "\n",
      "    accuracy                           0.62      5663\n",
      "   macro avg       0.64      0.41      0.50      5663\n",
      "weighted avg       0.96      0.62      0.75      5663\n",
      "\n",
      "Epoch 2: Test Metrics: Accuracy=0.619283065512979, Precision=0.9582539971295336, Recall=0.619283065512979, F1 Score=0.7506796850347005\n",
      "-- Epoch 4 Started --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8e537cc40c4084ada6105afc904b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Average Training Loss: 0.004058925231005676\n",
      "Epoch 4: Average Validation Loss: 0.008121631207301262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bcfd874a794b3d9049fc751d568cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           O       0.00      0.00      0.00         0\n",
      "           H       0.96      0.75      0.85      2789\n",
      "           T       0.94      0.63      0.75      2874\n",
      "\n",
      "    accuracy                           0.69      5663\n",
      "   macro avg       0.63      0.46      0.53      5663\n",
      "weighted avg       0.95      0.69      0.80      5663\n",
      "\n",
      "Epoch 3: Test Metrics: Accuracy=0.6899170051209607, Precision=0.9515085813917117, Recall=0.6899170051209607, F1 Score=0.7987299581863723\n",
      "-- Epoch 5 Started --\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391d3c884dd6409ba1a5e230d855ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Average Training Loss: 0.0037710621340328447\n",
      "Epoch 5: Average Validation Loss: 0.008757868234286124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd3c90ae99949a99e78aca52d16d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           O       0.00      0.00      0.00         0\n",
      "           H       0.95      0.68      0.79      2789\n",
      "           T       0.95      0.56      0.70      2874\n",
      "\n",
      "    accuracy                           0.62      5663\n",
      "   macro avg       0.63      0.41      0.50      5663\n",
      "weighted avg       0.95      0.62      0.75      5663\n",
      "\n",
      "Epoch 4: Test Metrics: Accuracy=0.6169874624757196, Precision=0.9505699955933502, Recall=0.6169874624757196, F1 Score=0.7467542855596536\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"-- Epoch {epoch + 1} Started --\")\n",
    "\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        model.zero_grad()\n",
    "\n",
    "        logits = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        loss = loss_fn(logits.view(-1, 3), b_labels.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch + 1}: Average Training Loss: {avg_train_loss}')\n",
    "    \n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            loss = loss_fn(logits.view(-1, 3), b_labels.view(-1))\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    print(f'Epoch {epoch + 1}: Average Validation Loss: {avg_val_loss}')\n",
    "\n",
    "        # Test Phase\n",
    "    test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(test_dataloader, model, label_map\n",
    "                                                                         \n",
    "    epoch_stats[\"accuracy\"].append(test_accuracy)\n",
    "    epoch_stats[\"precision\"].append(test_precision)\n",
    "    epoch_stats[\"recall\"].append(test_recall)\n",
    "    epoch_stats[\"f1_score\"].append(test_f1)\n",
    "    epoch_stats[\"train_loss\"].append(avg_train_loss)\n",
    "    epoch_stats[\"val_loss\"].append(avg_val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch}: Test Metrics: Accuracy={test_accuracy}, Precision={test_precision}, Recall={test_recall}, F1 Score={test_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd7849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep Learning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
